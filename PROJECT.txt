packetfs

The file system IS packets. Transfer is just references to the filesystem. The CPU is just tiny daemons, optimized to perform a SINGLE LLVM optimized instruction. Instruction appear to optimize at around 1.3 million parallel packets that make
up our packet CPU (pCPU). Each tiny daemon (1.3 million of them) only needs to do one tiny optimized LLVM operation. The result appears to be:

- Hugely sped up remote transfer due to protocol
- FASTER than a CPU can move files with real memory and a modern CPU.
- Packets are the key. Optimizations are the key. Pattern recognition and reduction of data are the key. Efficiency is key.
- Some things we've found: parallel processing is best at 1.3 million threads/packets - we are using this as our new base to start thinking of things in terms of this being our optimal unit (still need to fully verify)
- Transfers aren't theoretical anymore, they result in massive data reduction, and along with patern recognition, transfer at an EFFECTIVE SPEED of around 4PB/sec on a 1G line (unoptimized)

The numbers show that this should work. The code and tests show that this DOES work. However all of it is mixed in along with some stupid marketing BS. So here is the deal- NO MORE BS. Everything implemented should be
absolutely real, no more calculations, no more demo code, no more theory. ONLY IMPLEMENTATION!
