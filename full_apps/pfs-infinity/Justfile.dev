# Dev and local workflows (core-only)

# Include central variables
import "./justfile.vars"

# Start dev server (no Redis, no swarm)
dev-up:
    @echo "Starting pfs-infinity dev server on http://127.0.0.1:{{WS_PORT}}"
    PYTHONPATH=. {{VENV_PATH}}/bin/hypercorn -b 127.0.0.1:{{WS_PORT}} app.main:app --reload

# Back-compat default alias
up:
    just dev up

# Dev: install
# Uses central venv as per repo rules
dev-install:
    {{VENV_PATH}}/bin/python -m pip install -U pip setuptools wheel
    {{VENV_PATH}}/bin/python -m pip install fastapi hypercorn pydantic python-multipart pytest aioquic aiortc httpx websockets
    @echo "[dev] Installing pfcp command..."
    just transfer install-pfcp

# Tests (prefix per rules)
dev-test:
    PYTHONPATH=. {{VENV_PATH}}/bin/python -m pytest -q tests

# Clean artifacts (build, caches, logs)
dev-clean:
    bash scripts/clean.sh

# Dispatcher: `just dev <cmd>` (core)
dev cmd="help":
    @bash -eu -o pipefail -c '
    case "{{cmd}}" in \
      up) just dev-up ;; \
      install) just dev-install ;; \
      test|tests) just dev-test ;; \
      clean) just dev-clean ;; \
      milkshake) just dev-milkshake ;; \
      milkshake-aws-setup) just dev-milkshake-aws-setup ;; \
      milkshake-aws-query) just dev-milkshake-aws-query ;; \
      milkshake-aws-word) just dev-milkshake-aws-word ;; \
      vpcpu-init) just dev-vpcpu-init ;; \
      vpcpu-add) just dev-vpcpu-add ;; \
      vpcpu-list) just dev-vpcpu-list ;; \
      vpcpu-compute) just dev-vpcpu-compute ;; \
      spider-assets) just dev-spider-assets ;; \
      data-blob) just dev-data-blob ;; \
      bench-local) just dev-bench-local ;; \
      gh-build-manifests) just dev-gh-build-manifests ;; \
      gh-fetch-index) just dev-gh-fetch-index ;; \
      gh-eval) just dev-gh-eval ;; \
      *) echo "dev commands: up|install|test|clean|milkshake|milkshake-aws-setup|milkshake-aws-query|milkshake-aws-word|vpcpu-init|vpcpu-add|vpcpu-list|vpcpu-compute|spider-assets|data-blob|bench-local|gh-build-manifests|gh-fetch-index|gh-eval"; exit 2 ;; \
    esac'

# Asset spider: discovers range/cache-capable data URLs and records them
# Example:
#   just dev spider-assets seeds=https://releases.ubuntu.com/ allow=releases.ubuntu.com range=1
#   just dev spider-assets seeds=https://releases.ubuntu.com/ allow=releases.ubuntu.com range=1 compute_kind=edge_http compute_endpoint=http://localhost:5000

dev-spider-assets seeds allow range="0" compute_kind="" compute_endpoint="" max_pages="50":
    @echo "[spider] seeds={{seeds}} allow={{allow}} range={{range}} compute_kind={{compute_kind}}"
    bash scripts/spider/run_spider.sh "{{seeds}}" "{{allow}}" "{{max_pages}}" "{{range}}" "{{compute_kind}}" "{{compute_endpoint}}"

# Virtual pCPU registry and runner

dev-vpcpu-init:
    @mkdir -p var/vpcpu
    PYTHONPATH=. {{VENV_PATH}}/bin/python scripts/vpcpu/init_db.py

# Example:
# just dev vpcpu-add name=cf-worker kind=worker endpoint=https://pfs-edge.username.workers.dev attrs='{"latency_ms":25,"region":"SJC","concurrency":16}'

dev-vpcpu-add name kind endpoint attrs='{}':
    PYTHONPATH=. {{VENV_PATH}}/bin/python scripts/vpcpu/register_asset.py --name {{name}} --kind {{kind}} --endpoint {{endpoint}} --attrs '{{attrs}}'

# List assets

dev-vpcpu-list:
    PYTHONPATH=. {{VENV_PATH}}/bin/python scripts/vpcpu/list_assets.py

# Run a compute job via a provider endpoint
# Example: just dev vpcpu-compute kind=worker endpoint=https://pfs-edge... data_url=https://... instructions='[{"op":"counteq","imm":69,"offset":0,"length":1048576}]'

dev-vpcpu-compute kind endpoint data_url instructions:
    {{VENV_PATH}}/bin/python scripts/vpcpu/run_edge_compute_job.py --kind {{kind}} --endpoint {{endpoint}} --data-url {{data_url}} --instructions '{{instructions}}'

# Fast local blob generator (tmpfs)
# Example: just dev data-blob path=/dev/shm/pfs_blob.bin size_mb=256 pattern=zero

dev-data-blob path size_mb pattern="zero":
    bash scripts/data/make_blob.sh {{path}} {{size_mb}} {{pattern}}

# Local streaming bench against /compute on file:// path
# Example: just dev bench-local path=/dev/shm/pfs_blob.bin conc=8 wins=256 op=counteq imm=0

dev-bench-local path conc="8" wins="256" op="counteq" imm="0" endpoint="http://localhost:5000" winmb="1":
    {{VENV_PATH}}/bin/python scripts/bench/bench_local_stream.py --endpoint {{endpoint}} --path {{path}} --window-mb {{winmb}} --concurrency {{conc}} --max-windows {{wins}} --op {{op}} --imm {{imm}}

# Build GitHub Pages manifests (POC)
# Example:
#   just dev-gh-build-manifests path=/dev/shm/pfs_blob.bin base_url=https://USER.github.io/pfs-index/data/sha256/<digest>.bin

dev-gh-build-manifests path base_url provider_id="pages" window_mb="1" outdir="docs":
    PYTHONPATH=. {{VENV_PATH}}/bin/python scripts/publish/gh_build_manifests.py --object-path {{path}} --base-url {{base_url}} --provider-id {{provider_id}} --window-mb {{window_mb}} --output-dir {{outdir}}

# Fetch manifests from Pages and build a local window index
# Example:
#   just dev-gh-fetch-index manifest_url=https://USER.github.io/pfs-index/super_manifest.json out=var/vpcpu/index/pages_index.json

dev-gh-fetch-index manifest_url out="var/vpcpu/index/pages_index.json":
    PYTHONPATH=. {{VENV_PATH}}/bin/python scripts/publish/gh_fetch_index.py --manifest-url {{manifest_url}} --out {{out}}

# Evaluate a manifest by streaming windows via /compute
# Example:
#   just dev-gh-eval manifest_url=https://USER.github.io/pfs-index/super_manifest.json endpoint=http://localhost:5000 op=counteq imm=0


# Positional alternative: just dev-gh-eval https://...  http://localhost:5000 counteq 0

dev-gh-eval manifest_url endpoint op="counteq" imm="0" provider_id="pages" max="64" batch="16" conc="4":
    PYTHONPATH=. {{VENV_PATH}}/bin/python scripts/run/pfs_eval_manifest.py --manifest-url {{manifest_url}} --endpoint {{endpoint}} --op {{op}} --imm {{imm}} --provider-id {{provider_id}} --max-windows {{max}} --batch {{batch}} --concurrency {{conc}}

# Duration-based edge bench (writes var/vpcpu/baselines.jsonl)
# Example (positional): just dev-bench-edge /dev/shm/pfs_blob.bin 8 15 counteq 0

dev-bench-edge path conc="8" seconds="60" op="counteq" imm="0" endpoint="http://localhost:5000" winmb="1" label="local":
    {{VENV_PATH}}/bin/python scripts/bench/pfs_bench_edge.py --endpoint {{endpoint}} --path {{path}} --window-mb {{winmb}} --concurrency {{conc}} --duration-s {{seconds}} --op {{op}} --imm {{imm}} --label {{label}}

# Multi-port word program (cloud)
# Example:
#   just dev milkshake-aws-word target_ip=203.0.113.10 base=52000 bits=16 pattern=0b1011001110001111 log_group=/aws/vpc/flow-logs/my-vpc eni=eni-abc region=us-east-1 seconds=2 pps=2000

dev-milkshake-aws-word target_ip base pattern log_group eni bits="16" pps="2000" seconds="2" minutes="5" region="" prefer_action="ACCEPT" threshold="1":
    @echo "[milkshake:aws] word program to {{target_ip}} base={{base}} bits={{bits}} pattern={{pattern}} region={{region}}"
    bash scripts/cloud_milkshake/run_word.sh "{{target_ip}}" "{{base}}" "{{bits}}" "{{pattern}}" "{{pps}}" "{{seconds}}" "{{log_group}}" "{{eni}}" "{{minutes}}" "{{region}}" "{{prefer_action}}" "{{threshold}}"

# Milkshake (cloud, AWS VPC Flow Logs)
# NOTE: requires AWS CLI configured; we do not pass secrets inline

dev-milkshake-aws-setup vpc_id region log_group role="FlowLogsToCloudWatch":
    @echo "[milkshake:aws] setting up VPC Flow Logs: vpc={{vpc_id}} log_group={{log_group}} role={{role}} region={{region}}"
    bash scripts/cloud_milkshake/aws_flowlogs_setup.sh {{vpc_id}} {{log_group}} {{role}} {{region}}

# Example filter by ENI + UDP port
# protocol: 17=UDP, 6=TCP

dev-milkshake-aws-query log_group interface_id dstport protocol="17" minutes="5" region="":
    @echo "[milkshake:aws] querying flow logs: lg={{log_group}} eni={{interface_id}} port={{dstport}} proto={{protocol}} region={{region}}"
    bash scripts/cloud_milkshake/run_flowlogs_query.sh "{{log_group}}" "{{interface_id}}" "{{dstport}}" "{{protocol}}" "{{minutes}}" "{{region}}"

# Milkshake (firewall compute) helpers
# Requires sudo for nft (we set up counters only)

dev-milkshake port="51999" seconds="1" pps="5000" payload="":
    @echo "[milkshake] setting up nftables counter on UDP dport={{port}}"
    bash scripts/milkshake/nft_setup.sh {{port}}
    bash scripts/milkshake/nft_reset.sh {{port}}
    @echo "[milkshake] sending UDP probes: host=127.0.0.1 port={{port}} pps={{pps}} seconds={{seconds}}"
    python3 scripts/milkshake/udp_probe.py --host 127.0.0.1 --port {{port}} --pps {{pps}} --seconds {{seconds}} --payload "{{payload}}"
    @echo "[milkshake] reading counters"
    bash scripts/milkshake/nft_read.sh {{port}} | awk '{ print "packets="$1" bytes="$2 }'
